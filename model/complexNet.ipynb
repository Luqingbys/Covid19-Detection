{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.signal import get_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_kernels(win_len, win_inc, fft_len, win_type=None, invers=False):\n",
    "    ''' \n",
    "    使用STFT核初始化卷积/逆卷积模块（即ConvSTFT/ConviSTFT）\n",
    "    返回: 经STFT得到的kernel和window\n",
    "    '''\n",
    "    if win_type == 'None' or win_type is None:\n",
    "        window = np.ones(win_len)\n",
    "    else:\n",
    "        # **0.5   这里window是一个长度为win_len的一维张量\n",
    "        window = get_window(win_type, win_len, fftbins=True)\n",
    "\n",
    "    N = fft_len\n",
    "    # np.fft.rfft(a) 计算实际输入的一维离散傅里叶变换\n",
    "    # fourier_basis尺寸: (400, 257), dtype='complex'\n",
    "    fourier_basis = np.fft.rfft(np.eye(N))[:win_len]\n",
    "    real_kernel = np.real(fourier_basis)  # 实部, dtype='float', (400, 257)\n",
    "    imag_kernel = np.imag(fourier_basis)  # 虚部, dtype='float', (400, 257)\n",
    "    # 将实部和虚部按列拼接，扩展列，经转置，尺寸为(514, 400)\n",
    "    kernel = np.concatenate([real_kernel, imag_kernel], 1).T\n",
    "\n",
    "    # invers默认为False\n",
    "    if invers:\n",
    "        # 求kernel矩阵（二维张量）的伪逆，尺寸不变\n",
    "        kernel = np.linalg.pinv(kernel).T\n",
    "\n",
    "    kernel = kernel*window  # kernel: (514, 400), window: (400,)\n",
    "    kernel = kernel[:, None, :]  # 同样地，kernel维度扩展成三维，返回的时候转为tensor类型\n",
    "    return torch.from_numpy(kernel.astype(np.float32)), torch.from_numpy(window[None, :, None].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSTFT(nn.Module):\n",
    "    '''\n",
    "    短时傅立叶变换卷积模块\n",
    "    win_type='hamming'\n",
    "    '''\n",
    "\n",
    "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
    "        ''' \n",
    "        win_len:\n",
    "        win_inc:\n",
    "        fft_len: \n",
    "        win_type: \n",
    "        '''\n",
    "        super(ConvSTFT, self).__init__()\n",
    "\n",
    "        if fft_len == None:\n",
    "            self.fft_len = np.int(2**np.ceil(np.log2(win_len)))\n",
    "        else:\n",
    "            self.fft_len = fft_len\n",
    "\n",
    "        kernel, _ = init_kernels(win_len, win_inc, self.fft_len, win_type)\n",
    "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
    "        self.register_buffer('weight', kernel)  # 将kernel注册为参数'weight', 期望将其保存\n",
    "        self.feature_type = feature_type  # 类型，默认为real，也可以是complex\n",
    "        self.stride = win_inc\n",
    "        self.win_len = win_len\n",
    "        self.dim = self.fft_len\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if inputs.dim() == 2:  # inputs: (1, 1, 128000)\n",
    "            inputs = torch.unsqueeze(inputs, 1)\n",
    "        inputs = F.pad(\n",
    "            inputs, [self.win_len-self.stride, self.win_len-self.stride])  # F.pad()填充，从(1, 1, 128000)的第二维度左边、右边填充 self.win_len-self.stride=160 个0\n",
    "        # 卷积核kernel使用上面init_kernels()得到的核，相比于conv2d，conv1d接收的张量尺寸中有一维被忽略\n",
    "        outputs = F.conv1d(inputs, self.weight, stride=self.stride)\n",
    "\n",
    "        if self.feature_type == 'complex':\n",
    "            return outputs\n",
    "        else:\n",
    "            dim = self.dim//2+1\n",
    "            real = outputs[:, :dim, :]\n",
    "            imag = outputs[:, dim:, :]\n",
    "            # 从笛卡尔坐标映射到极坐标，real、imag变换为幅度mags、相位phase\n",
    "            mags = torch.sqrt(real**2+imag**2)\n",
    "            phase = torch.atan2(imag, real)\n",
    "            return mags, phase\n",
    "\n",
    "\n",
    "class ConviSTFT(nn.Module):\n",
    "    ''' \n",
    "    短时傅立叶变换逆卷积模块\n",
    "    '''\n",
    "\n",
    "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
    "        super(ConviSTFT, self).__init__()\n",
    "        if fft_len == None:\n",
    "            self.fft_len = np.int(2**np.ceil(np.log2(win_len)))\n",
    "        else:\n",
    "            self.fft_len = fft_len\n",
    "        kernel, window = init_kernels(\n",
    "            win_len, win_inc, self.fft_len, win_type, invers=True)\n",
    "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.feature_type = feature_type\n",
    "        self.win_type = win_type\n",
    "        self.win_len = win_len\n",
    "        self.stride = win_inc\n",
    "        self.stride = win_inc\n",
    "        self.dim = self.fft_len\n",
    "        self.register_buffer('window', window)  # self.window: (1, win_len, 1)\n",
    "        self.register_buffer('enframe', torch.eye(win_len)[:, None, :])\n",
    "\n",
    "    def forward(self, inputs, phase=None):\n",
    "        \"\"\"\n",
    "        inputs : [B, N+2, T] (complex spec) or [B, N//2+1, T] (mags)，样例中尺寸为(1, 514, 1283)\n",
    "        phase: [B, N//2+1, T] (if not none)\n",
    "        \"\"\"\n",
    "\n",
    "        if phase is not None:\n",
    "            real = inputs*torch.cos(phase)\n",
    "            imag = inputs*torch.sin(phase)\n",
    "            inputs = torch.cat([real, imag], 1)\n",
    "        outputs = F.conv_transpose1d(\n",
    "            inputs, self.weight, stride=self.stride)  # outputs: (1, 1, 128600)\n",
    "\n",
    "        # this is from torch-stft: https://github.com/pseeth/torch-stft\n",
    "        # repeat()对各个维度的长度进行拓展\n",
    "        t = self.window.repeat(1, 1, inputs.size(-1))**2\n",
    "        coff = F.conv_transpose1d(\n",
    "            t, self.enframe, stride=self.stride)  # coff: (1, 1, 128600)\n",
    "        outputs = outputs/(coff+1e-8)\n",
    "        # outputs = torch.where(coff == 0, outputs, outputs/coff)\n",
    "        outputs = outputs[..., self.win_len -\n",
    "                          self.stride:-(self.win_len-self.stride)]  # outputs: (1, 1, 128000), [..., c]表示取出最里面一维的全部第c位序的元素\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex_data(specs, fft_length=512, lens=None):\n",
    "    # print('======== module dc_crn.py, DCCRN ========')\n",
    "    # print('inputs: ', inputs.shape)\n",
    "    # specs = self.stft(inputs) # specs尺寸为二维，这就是频域信号\n",
    "    print('after ConvSTFT: ', specs.shape)\n",
    "    real = specs[:, :fft_length//2+1]\n",
    "    imag = specs[:, fft_length//2+1:]\n",
    "    # 振幅信息\n",
    "    spec_mags = torch.sqrt(real**2+imag**2+1e-8) # 振幅，即实部和虚部的平方和的算术平方根\n",
    "    spec_mags = spec_mags\n",
    "    print('振幅: ', spec_mags.shape)\n",
    "    # 相位信息\n",
    "    spec_phase = torch.atan2(imag, real) # 相位，即虚部与实部的比值的反正切函数值\n",
    "    spec_phase = spec_phase\n",
    "    print('相位: ', spec_phase.shape)\n",
    "\n",
    "    cspecs = torch.stack([real, imag], 1)\n",
    "    cspecs = cspecs[:, :, 1:]\n",
    "    print('实部和虚部: ', cspecs.shape)\n",
    "    return cspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavieComplexLSTM(nn.Module):\n",
    "    '''复LSTM'''\n",
    "    def __init__(self, input_size, hidden_size, projection_dim=None, bidirectional=False, batch_first=False):\n",
    "        super(NavieComplexLSTM, self).__init__()\n",
    "\n",
    "        self.input_dim = input_size//2\n",
    "        self.rnn_units = hidden_size//2\n",
    "        # real_lstm、imag_lstm本质上都是朴素的LSTM，只不过前者接受实部，后者接收虚部\n",
    "        self.real_lstm = nn.LSTM(self.input_dim, self.rnn_units,\n",
    "                                 num_layers=1, bidirectional=bidirectional, batch_first=False)\n",
    "        self.imag_lstm = nn.LSTM(self.input_dim, self.rnn_units,\n",
    "                                 num_layers=1, bidirectional=bidirectional, batch_first=False)\n",
    "        if bidirectional:\n",
    "            bidirectional = 2\n",
    "        else:\n",
    "            bidirectional = 1\n",
    "        if projection_dim is not None:\n",
    "            self.projection_dim = projection_dim//2\n",
    "            self.r_trans = nn.Linear(\n",
    "                self.rnn_units*bidirectional, self.projection_dim)\n",
    "            self.i_trans = nn.Linear(\n",
    "                self.rnn_units*bidirectional, self.projection_dim)\n",
    "        else:\n",
    "            self.projection_dim = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if isinstance(inputs, list):\n",
    "            real, imag = inputs\n",
    "        elif isinstance(inputs, torch.Tensor):\n",
    "            real, imag = torch.chunk(inputs, -1)\n",
    "        r2r_out = self.real_lstm(real)[0]\n",
    "        r2i_out = self.imag_lstm(real)[0]\n",
    "        i2r_out = self.real_lstm(imag)[0]\n",
    "        i2i_out = self.imag_lstm(imag)[0]\n",
    "        real_out = r2r_out - i2i_out\n",
    "        imag_out = i2r_out + r2i_out\n",
    "        if self.projection_dim is not None:\n",
    "            real_out = self.r_trans(real_out)\n",
    "            imag_out = self.i_trans(imag_out)\n",
    "        # print(real_out.shape,imag_out.shape)\n",
    "        return [real_out, imag_out]\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        self.imag_lstm.flatten_parameters()\n",
    "        self.real_lstm.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cPReLU(nn.Module):\n",
    "    '''复激活层'''\n",
    "\n",
    "    def __init__(self, complex_axis=1):\n",
    "        super(cPReLU, self).__init__()\n",
    "        # nn.PReLU()，一种激活函数，类似于ReLU()，表达式为Parametric ReLU，PReLU(x) = max(x, 0) + a*max(0, x)，其中参数a可学习\n",
    "        # https://blog.csdn.net/flyfish1986/article/details/106649011\n",
    "        self.r_prelu = nn.PReLU()\n",
    "        self.i_prelu = nn.PReLU()\n",
    "        self.complex_axis = complex_axis\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # torch.chunk(tensor, num, axis)，在tensor的第axis维度上进行分块，inputs是一个复张量，complex_axis指的是虚部维度，得到复张量的实部和虚部\n",
    "        real, imag = torch.chunk(inputs, 2, self.complex_axis)\n",
    "        real = self.r_prelu(real)\n",
    "        imag = self.i_prelu(imag)\n",
    "        # torch.cat()，在指定维度上对tensor进行拼接，恢复到原来的inputs\n",
    "        return torch.cat([real, imag], self.complex_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConv2d(nn.Module):\n",
    "    '''复卷积层'''\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=(1, 1),\n",
    "        stride=(1, 1),\n",
    "        padding=(0, 0),\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        causal=True,\n",
    "        complex_axis=1,\n",
    "    ):\n",
    "        '''\n",
    "            in_channels: real+imag，输入通道数\n",
    "            out_channels: real+imag ，输出通道数\n",
    "            kernel_size : input [B,C,D,T] kernel size in [D,T]，卷积核尺寸\n",
    "            stride: 步长\n",
    "            padding: input [B,C,D,T] padding in [D,T]，填充\n",
    "            dilation: 是否采用空洞卷积，1表示不采用\n",
    "            groups: 决定是否采用分组卷积\n",
    "            causal: if causal, will padding time dimension's left side,\n",
    "                    otherwise both\n",
    "            complex_axis: 默认为1，指的是在哪一个维度上将张量拆分为实部和虚部\n",
    "\n",
    "        '''\n",
    "        super(ComplexConv2d, self).__init__()\n",
    "        self.in_channels = in_channels//2 # 为输入张量通道数的一半，输入张量一半为实部一半为虚部\n",
    "        self.out_channels = out_channels//2\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.causal = causal\n",
    "        self.groups = groups\n",
    "        self.dilation = dilation\n",
    "        self.complex_axis = complex_axis\n",
    "        # 复卷积层本质上是朴素的卷积层\n",
    "        self.real_conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, self.stride, padding=[\n",
    "                                   self.padding[0], 0], dilation=self.dilation, groups=self.groups)\n",
    "        self.imag_conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, self.stride, padding=[\n",
    "                                   self.padding[0], 0], dilation=self.dilation, groups=self.groups)\n",
    "        \n",
    "        # torch.nn.init.normal_(tensor, mean, std)，用正态分布给张量初始化\n",
    "        nn.init.normal_(self.real_conv.weight.data, std=0.05)\n",
    "        nn.init.normal_(self.imag_conv.weight.data, std=0.05)\n",
    "        # torch.nn.init.constant_(tensor, val)，使用val来填充tensor\n",
    "        nn.init.constant_(self.real_conv.bias, 0.)\n",
    "        nn.init.constant_(self.imag_conv.bias, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.padding[1] != 0 and self.causal:\n",
    "            inputs = F.pad(inputs, [self.padding[1], 0, 0, 0]) # if causal，inputs左边补零，个数为self.padding[1]\n",
    "        else:\n",
    "            inputs = F.pad(inputs, [self.padding[1], self.padding[1], 0, 0]) # 不然inputs两边都补零，个数均为self.padding[1]\n",
    "\n",
    "        if self.complex_axis == 0:\n",
    "            real = self.real_conv(inputs)\n",
    "            imag = self.imag_conv(inputs)\n",
    "            real2real, imag2real = torch.chunk(real, 2, self.complex_axis)\n",
    "            real2imag, imag2imag = torch.chunk(imag, 2, self.complex_axis)\n",
    "\n",
    "        else:\n",
    "            if isinstance(inputs, torch.Tensor):\n",
    "                real, imag = torch.chunk(inputs, 2, self.complex_axis) # chunk()数组拆分，沿着指定维度拆分为指定数量的tensor\n",
    "            print('before this ComplexConv2d: ')\n",
    "            print('实部：', real.shape)\n",
    "            print('虚部：', imag.shape)\n",
    "            real2real = self.real_conv(real,)\n",
    "            imag2imag = self.imag_conv(imag,)\n",
    "\n",
    "            real2imag = self.imag_conv(real)\n",
    "            imag2real = self.real_conv(imag)\n",
    "\n",
    "        real = real2real - imag2imag\n",
    "        imag = real2imag + imag2real\n",
    "        out = torch.cat([real, imag], self.complex_axis) # 沿着复数轴将实部和虚部拼接起来，real和imag均为四维张量\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexBatchNorm(torch.nn.Module):\n",
    "    '''复批标准化层'''\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True, complex_axis=1):\n",
    "        super(ComplexBatchNorm, self).__init__()\n",
    "        self.num_features = num_features//2\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "        self.complex_axis = complex_axis\n",
    "\n",
    "        if self.affine:\n",
    "            self.Wrr = torch.nn.Parameter(torch.Tensor(self.num_features))\n",
    "            self.Wri = torch.nn.Parameter(torch.Tensor(self.num_features))\n",
    "            self.Wii = torch.nn.Parameter(torch.Tensor(self.num_features))\n",
    "            self.Br = torch.nn.Parameter(torch.Tensor(self.num_features))\n",
    "            self.Bi = torch.nn.Parameter(torch.Tensor(self.num_features))\n",
    "        else:\n",
    "            self.register_parameter('Wrr', None)\n",
    "            self.register_parameter('Wri', None)\n",
    "            self.register_parameter('Wii', None)\n",
    "            self.register_parameter('Br',  None)\n",
    "            self.register_parameter('Bi',  None)\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('RMr',  torch.zeros(self.num_features))\n",
    "            self.register_buffer('RMi',  torch.zeros(self.num_features))\n",
    "            self.register_buffer('RVrr', torch.ones(self.num_features))\n",
    "            self.register_buffer('RVri', torch.zeros(self.num_features))\n",
    "            self.register_buffer('RVii', torch.ones(self.num_features))\n",
    "            self.register_buffer('num_batches_tracked',\n",
    "                                 torch.tensor(0, dtype=torch.long))\n",
    "        else:\n",
    "            self.register_parameter('RMr',                 None)\n",
    "            self.register_parameter('RMi',                 None)\n",
    "            self.register_parameter('RVrr',                None)\n",
    "            self.register_parameter('RVri',                None)\n",
    "            self.register_parameter('RVii',                None)\n",
    "            self.register_parameter('num_batches_tracked', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_running_stats(self):\n",
    "        if self.track_running_stats:\n",
    "            self.RMr.zero_()\n",
    "            self.RMi.zero_()\n",
    "            self.RVrr.fill_(1)\n",
    "            self.RVri.zero_()\n",
    "            self.RVii.fill_(1)\n",
    "            self.num_batches_tracked.zero_()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            self.Br.data.zero_()\n",
    "            self.Bi.data.zero_()\n",
    "            self.Wrr.data.fill_(1)\n",
    "            self.Wri.data.uniform_(-.9, +.9)  # W will be positive-definite\n",
    "            self.Wii.data.fill_(1)\n",
    "\n",
    "    def _check_input_dim(self, xr, xi):\n",
    "        assert(xr.shape == xi.shape)\n",
    "        assert(xr.size(1) == self.num_features)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #self._check_input_dim(xr, xi)\n",
    "\n",
    "        xr, xi = torch.chunk(inputs, 2, axis=self.complex_axis) # 切分出来实部和虚部\n",
    "        exponential_average_factor = 0.0\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            self.num_batches_tracked += 1\n",
    "            if self.momentum is None:  # use cumulative moving average\n",
    "                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n",
    "            else:  # use exponential moving average\n",
    "                exponential_average_factor = self.momentum\n",
    "\n",
    "        #\n",
    "        # NOTE: The precise meaning of the \"training flag\" is:\n",
    "        #       True:  Normalize using batch   statistics, update running statistics\n",
    "        #              if they are being collected.\n",
    "        #       False: Normalize using running statistics, ignore batch   statistics.\n",
    "        #\n",
    "        training = self.training or not self.track_running_stats\n",
    "        redux = [i for i in reversed(range(xr.dim())) if i != 1]\n",
    "        vdim = [1] * xr.dim()\n",
    "        vdim[1] = xr.size(1)\n",
    "\n",
    "        #\n",
    "        # Mean M Computation and Centering\n",
    "        #\n",
    "        # Includes running mean update if training and running.\n",
    "        #\n",
    "        if training:\n",
    "            Mr, Mi = xr, xi\n",
    "            for d in redux:\n",
    "                Mr = Mr.mean(d, keepdim=True)\n",
    "                Mi = Mi.mean(d, keepdim=True)\n",
    "            if self.track_running_stats:\n",
    "                self.RMr.lerp_(Mr.squeeze(), exponential_average_factor)\n",
    "                self.RMi.lerp_(Mi.squeeze(), exponential_average_factor)\n",
    "        else:\n",
    "            Mr = self.RMr.view(vdim)\n",
    "            Mi = self.RMi.view(vdim)\n",
    "        xr, xi = xr-Mr, xi-Mi\n",
    "\n",
    "        #\n",
    "        # Variance Matrix V Computation\n",
    "        #\n",
    "        # Includes epsilon numerical stabilizer/Tikhonov regularizer.\n",
    "        # Includes running variance update if training and running.\n",
    "        #\n",
    "        if training:\n",
    "            Vrr = xr * xr\n",
    "            Vri = xr * xi\n",
    "            Vii = xi * xi\n",
    "            for d in redux:\n",
    "                Vrr = Vrr.mean(d, keepdim=True)\n",
    "                Vri = Vri.mean(d, keepdim=True)\n",
    "                Vii = Vii.mean(d, keepdim=True)\n",
    "            if self.track_running_stats:\n",
    "                self.RVrr.lerp_(Vrr.squeeze(), exponential_average_factor)\n",
    "                self.RVri.lerp_(Vri.squeeze(), exponential_average_factor)\n",
    "                self.RVii.lerp_(Vii.squeeze(), exponential_average_factor)\n",
    "        else:\n",
    "            Vrr = self.RVrr.view(vdim)\n",
    "            Vri = self.RVri.view(vdim)\n",
    "            Vii = self.RVii.view(vdim)\n",
    "        Vrr = Vrr + self.eps\n",
    "        Vri = Vri\n",
    "        Vii = Vii + self.eps\n",
    "\n",
    "        #\n",
    "        # Matrix Inverse Square Root U = V^-0.5\n",
    "        #\n",
    "        # sqrt of a 2x2 matrix,\n",
    "        # - https://en.wikipedia.org/wiki/Square_root_of_a_2_by_2_matrix\n",
    "        tau = Vrr + Vii\n",
    "        delta = torch.addcmul(Vrr * Vii, -1, Vri, Vri)\n",
    "        s = delta.sqrt()\n",
    "        t = (tau + 2*s).sqrt()\n",
    "\n",
    "        # matrix inverse, http://mathworld.wolfram.com/MatrixInverse.html\n",
    "        rst = (s * t).reciprocal()\n",
    "        Urr = (s + Vii) * rst\n",
    "        Uii = (s + Vrr) * rst\n",
    "        Uri = (- Vri) * rst\n",
    "\n",
    "        #\n",
    "        # Optionally left-multiply U by affine weights W to produce combined\n",
    "        # weights Z, left-multiply the inputs by Z, then optionally bias them.\n",
    "        #\n",
    "        # y = Zx + B\n",
    "        # y = WUx + B\n",
    "        # y = [Wrr Wri][Urr Uri] [xr] + [Br]\n",
    "        #     [Wir Wii][Uir Uii] [xi]   [Bi]\n",
    "        #\n",
    "        if self.affine:\n",
    "            Wrr, Wri, Wii = self.Wrr.view(\n",
    "                vdim), self.Wri.view(vdim), self.Wii.view(vdim)\n",
    "            Zrr = (Wrr * Urr) + (Wri * Uri)\n",
    "            Zri = (Wrr * Uri) + (Wri * Uii)\n",
    "            Zir = (Wri * Urr) + (Wii * Uri)\n",
    "            Zii = (Wri * Uri) + (Wii * Uii)\n",
    "        else:\n",
    "            Zrr, Zri, Zir, Zii = Urr, Uri, Uri, Uii\n",
    "\n",
    "        yr = (Zrr * xr) + (Zri * xi)\n",
    "        yi = (Zir * xr) + (Zii * xi)\n",
    "\n",
    "        if self.affine:\n",
    "            yr = yr + self.Br.view(vdim)\n",
    "            yi = yi + self.Bi.view(vdim)\n",
    "\n",
    "        outputs = torch.cat([yr, yi], self.complex_axis)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{num_features}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
    "            'track_running_stats={track_running_stats}'.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConvBlock(nn.Module):\n",
    "    ''' \n",
    "    复卷积块\n",
    "    complex_axis: 默认按照第一维度进行分割\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch, kernel, num_features, complex_axis=1) -> None:\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(ComplexConv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=kernel), ComplexBatchNorm(num_features=num_features), cPReLU(complex_axis=complex_axis))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.block(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 172032])\n",
      "after ConvSTFT:  torch.Size([1, 514, 1723])\n",
      "振幅:  torch.Size([1, 257, 1723])\n",
      "相位:  torch.Size([1, 257, 1723])\n",
      "实部和虚部:  torch.Size([1, 2, 256, 1723])\n",
      "data:  torch.Size([1, 2, 256, 1723])\n",
      "----------------------\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 1, 256, 1723])\n",
      "虚部： torch.Size([1, 1, 256, 1723])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [2, 0, 3, 3], expected input[1, 1, 256, 1723] to have 0 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [75], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m ComplexConvBlock(in_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, kernel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [74], line 11\u001b[0m, in \u001b[0;36mComplexConvBlock.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [72], line 70\u001b[0m, in \u001b[0;36mComplexConv2d.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m实部：\u001b[39m\u001b[38;5;124m'\u001b[39m, real\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m虚部：\u001b[39m\u001b[38;5;124m'\u001b[39m, imag\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 70\u001b[0m real2real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m imag2imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimag_conv(imag,)\n\u001b[0;32m     73\u001b[0m real2imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimag_conv(real)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\covid19-detection\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [2, 0, 3, 3], expected input[1, 1, 256, 1723] to have 0 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "# 使用torchaudio读取音频\n",
    "data, sr = torchaudio.load('../00aaf6b0-be51-4518-b8ab-15bc3a7c6439.wav')\n",
    "# data, sr = torchaudio.load('../0a469058-bbb8-4fe9-90a3-30cbe97275a5.wav')\n",
    "print(data.shape)\n",
    "# data = data[None, :, :].numpy()\n",
    "data = data.clamp_(-1, 1)\n",
    "pre_model = ConvSTFT(win_len=400, win_inc=100, fft_len=512, feature_type='complex')\n",
    "data = pre_model(data)\n",
    "data = get_complex_data(specs=data)\n",
    "print('data: ', data.shape)\n",
    "print('----------------------')\n",
    "model = ComplexConvBlock(in_ch=1, out_ch=5, kernel=(3, 3), num_features=256)\n",
    "output = model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCCRN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_layers=2,\n",
    "        rnn_units=128,\n",
    "        win_len=400,\n",
    "        win_inc=100,\n",
    "        fft_len=512,\n",
    "        win_type='hann',\n",
    "        masking_mode='E',\n",
    "        use_clstm=False,\n",
    "        use_cbn=False,\n",
    "        kernel_size=5,\n",
    "        kernel_num=[16, 32, 64, 128, 256, 256],\n",
    "        ffn_input=(2, 10)\n",
    "    ):\n",
    "    # 原写法是win_type='hanning'，会报错，理由应该是scipy.signal.get_window(window, ...)中的window类型不包括hanning，类型支持hann、hamming等\n",
    "    # https://vimsky.com/examples/usage/python-scipy.signal.get_window.html\n",
    "        ''' \n",
    "\n",
    "            rnn_layers: the number of lstm layers in the crn,\n",
    "            rnn_units: for clstm, rnn_units = real+imag\n",
    "\n",
    "        '''\n",
    "\n",
    "        super(DCCRN, self).__init__()\n",
    "\n",
    "        # for fft\n",
    "        self.win_len = win_len\n",
    "        self.win_inc = win_inc\n",
    "        self.fft_len = fft_len\n",
    "        self.win_type = win_type\n",
    "\n",
    "        input_dim = win_len\n",
    "        output_dim = win_len\n",
    "\n",
    "        self.rnn_units = rnn_units\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = rnn_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        #self.kernel_num = [2, 8, 16, 32, 128, 128, 128]\n",
    "        #self.kernel_num = [2, 16, 32, 64, 128, 256, 256]\n",
    "        self.kernel_num = [2]+kernel_num # 默认是七个kernel_num\n",
    "        self.masking_mode = masking_mode\n",
    "        self.use_clstm = use_clstm\n",
    "        self.ffn_input = ffn_input\n",
    "\n",
    "        # bidirectional=True\n",
    "        bidirectional = False\n",
    "        fac = 2 if bidirectional else 1\n",
    "\n",
    "        fix = True\n",
    "        self.fix = fix\n",
    "        # ConvSTFT\n",
    "        self.stft = ConvSTFT(self.win_len, self.win_inc,\n",
    "                             fft_len, self.win_type, 'complex', fix=fix)\n",
    "        # 逆ConvSTFT\n",
    "        self.istft = ConviSTFT(self.win_len, self.win_inc,\n",
    "                               fft_len, self.win_type, 'complex', fix=fix)\n",
    "\n",
    "        # 编码器，多次卷积块（每一个卷积块由多个卷积层+批标准化+激活函数构成）\n",
    "        self.encoder = nn.ModuleList()\n",
    "        # 解码器，多次逆卷积\n",
    "        self.decoder = nn.ModuleList()\n",
    "        # 添加编码器Encoder，默认添加6个，1个Encoder由1个复卷积层、复标准化层和复激活层组成\n",
    "        for idx in range(len(self.kernel_num)-1):\n",
    "            self.encoder.append(\n",
    "                nn.Sequential(\n",
    "                    #nn.ConstantPad2d([0, 0, 0, 0], 0),\n",
    "                    ComplexConv2d(\n",
    "                        self.kernel_num[idx],\n",
    "                        self.kernel_num[idx+1],\n",
    "                        kernel_size=(self.kernel_size, 2),\n",
    "                        stride=(2, 1),\n",
    "                        padding=(2, 1)\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(\n",
    "                        self.kernel_num[idx+1]) if not use_cbn else ComplexBatchNorm(self.kernel_num[idx+1]),\n",
    "                    nn.PReLU()\n",
    "                )\n",
    "            )\n",
    "        hidden_dim = self.fft_len//(2**(len(self.kernel_num)))\n",
    "\n",
    "        if self.use_clstm:\n",
    "            rnns = []\n",
    "            # rnns默认添加2个复LSTM（rnn_layers=2）\n",
    "            for idx in range(rnn_layers):\n",
    "                rnns.append(\n",
    "                    NavieComplexLSTM(\n",
    "                        input_size=hidden_dim *\n",
    "                        self.kernel_num[-1] if idx == 0 else self.rnn_units,\n",
    "                        hidden_size=self.rnn_units,\n",
    "                        bidirectional=bidirectional,\n",
    "                        batch_first=False,\n",
    "                        projection_dim=hidden_dim *\n",
    "                        self.kernel_num[-1] if idx == rnn_layers-1 else None,\n",
    "                    )\n",
    "                )\n",
    "                # 复LSTM层\n",
    "                self.enhance = nn.Sequential(*rnns)\n",
    "                self.linear = nn.Linear(self.ffn_input[0]*self.ffn_input[1]*kernel_num[-1], 2)\n",
    "        else:\n",
    "            # 不使用复lstm\n",
    "            self.enhance = nn.LSTM(\n",
    "                input_size=hidden_dim*self.kernel_num[-1],\n",
    "                hidden_size=self.rnn_units,\n",
    "                num_layers=2,\n",
    "                dropout=0.0,\n",
    "                bidirectional=bidirectional,\n",
    "                batch_first=False\n",
    "            )\n",
    "            self.tranform = nn.Linear(\n",
    "                self.rnn_units * fac, hidden_dim*self.kernel_num[-1])\n",
    "        self.avg = nn.AdaptiveAvgPool2d(self.ffn_input)\n",
    "\n",
    "    \n",
    "    def forward(self, inputs, lens=None):\n",
    "        complex_data = self.get_amp_phase(inputs, lens)\n",
    "\n",
    "        out = complex_data\n",
    "        encoder_out = []\n",
    "        print('before encoders: ', out.shape)\n",
    "\n",
    "        # 通过Encoder\n",
    "        for idx, layer in enumerate(self.encoder):\n",
    "            out = layer(out)\n",
    "        #    print('encoder', out.size())\n",
    "            encoder_out.append(out)\n",
    "\n",
    "        # out尺寸为四维: (B, C, D, L)\n",
    "        print('after encoders: ', out.shape)\n",
    "        batch_size, channels, dims, lengths = out.size()\n",
    "        out = out.permute(3, 0, 1, 2) # 将out进行转置操作, out: (L, B, C, D)\n",
    "\n",
    "        # 通过lstm\n",
    "        print('before clstm: ', out.shape)\n",
    "        if self.use_clstm:\n",
    "            r_rnn_in = out[:, :, :channels//2]\n",
    "            i_rnn_in = out[:, :, channels//2:]\n",
    "            r_rnn_in = torch.reshape(\n",
    "                r_rnn_in, [lengths, batch_size, channels//2*dims])\n",
    "            i_rnn_in = torch.reshape(\n",
    "                i_rnn_in, [lengths, batch_size, channels//2*dims])\n",
    "\n",
    "            r_rnn_in, i_rnn_in = self.enhance([r_rnn_in, i_rnn_in])\n",
    "\n",
    "            r_rnn_in = torch.reshape(\n",
    "                r_rnn_in, [lengths, batch_size, channels//2, dims])\n",
    "            i_rnn_in = torch.reshape(\n",
    "                i_rnn_in, [lengths, batch_size, channels//2, dims])\n",
    "            out = torch.cat([r_rnn_in, i_rnn_in], 2)\n",
    "            print('after clstm: ', out.shape)\n",
    "        else:\n",
    "            # to [L, B, C, D]\n",
    "            out = torch.reshape(out, [lengths, batch_size, channels*dims]) # out: (L, B, C*D)\n",
    "            out, _ = self.enhance(out)\n",
    "            out = self.tranform(out)\n",
    "            out = torch.reshape(out, [lengths, batch_size, channels, dims]) # out: (L, B, C, D)\n",
    "\n",
    "        print('the final output: ', out.shape)\n",
    "        out = out.permute(1, 2, 3, 0) # out: (B, C, D, L)\n",
    "        print('after permute: ', out.shape)\n",
    "        out = self.avg(out) # out: (B, C, ffn_input) == (B, C, D, L), ffn_input==(D, L)\n",
    "        print('after avg: ', out.shape)\n",
    "        out = out.view(1, -1) # out: (B, C*D*L)\n",
    "        print('before linear: ', out.shape)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def get_amp_phase(self, inputs, lens=None):\n",
    "        print('======== module dc_crn.py, DCCRN ========')\n",
    "        print('before ConvSTFT: ', inputs.shape)\n",
    "        specs = self.stft(inputs) # specs尺寸为二维，这就是频域信号\n",
    "        print('after ConvSTFT: ', specs.shape)\n",
    "        real = specs[:, :self.fft_len//2+1]\n",
    "        imag = specs[:, self.fft_len//2+1:]\n",
    "        # 振幅信息\n",
    "        spec_mags = torch.sqrt(real**2+imag**2+1e-8) # 振幅，即实部和虚部的平方和的算术平方根\n",
    "        spec_mags = spec_mags\n",
    "        print('振幅: ', spec_mags.shape)\n",
    "        # 相位信息\n",
    "        spec_phase = torch.atan2(imag, real) # 相位，即虚部与实部的比值的反正切函数值\n",
    "        spec_phase = spec_phase\n",
    "        print('相位: ', spec_phase.shape)\n",
    "\n",
    "        cspecs = torch.stack([real, imag], 1)\n",
    "        cspecs = cspecs[:, :, 1:]\n",
    "        print('实部和虚部: ', cspecs.shape)\n",
    "        return cspecs\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 172032])\n",
      "======== module dc_crn.py, DCCRN ========\n",
      "before ConvSTFT:  torch.Size([1, 172032])\n",
      "after ConvSTFT:  torch.Size([1, 514, 1723])\n",
      "振幅:  torch.Size([1, 257, 1723])\n",
      "相位:  torch.Size([1, 257, 1723])\n",
      "实部和虚部:  torch.Size([1, 2, 256, 1723])\n",
      "before encoders:  torch.Size([1, 2, 256, 1723])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 1, 256, 1724])\n",
      "虚部： torch.Size([1, 1, 256, 1724])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 16, 128, 1724])\n",
      "虚部： torch.Size([1, 16, 128, 1724])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 32, 64, 1724])\n",
      "虚部： torch.Size([1, 32, 64, 1724])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 64, 32, 1724])\n",
      "虚部： torch.Size([1, 64, 32, 1724])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 128, 16, 1724])\n",
      "虚部： torch.Size([1, 128, 16, 1724])\n",
      "before this ComplexConv2d: \n",
      "实部： torch.Size([1, 128, 8, 1724])\n",
      "虚部： torch.Size([1, 128, 8, 1724])\n",
      "after encoders:  torch.Size([1, 256, 4, 1723])\n",
      "before clstm:  torch.Size([1723, 1, 256, 4])\n",
      "after clstm:  torch.Size([1723, 1, 256, 4])\n",
      "the final output:  torch.Size([1723, 1, 256, 4])\n",
      "after permute:  torch.Size([1, 256, 4, 1723])\n",
      "after avg:  torch.Size([1, 256, 2, 10])\n",
      "before linear:  torch.Size([1, 5120])\n",
      "output:  torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 使用torchaudio读取音频\n",
    "data, sr = torchaudio.load('../00aaf6b0-be51-4518-b8ab-15bc3a7c6439.wav')\n",
    "print(data.shape)\n",
    "# data = data[None, :, :].numpy()\n",
    "data = data.clamp_(-1, 1)\n",
    "\n",
    "net = DCCRN(rnn_units=256, masking_mode='E', use_clstm=True,\n",
    "                kernel_num=[32, 64, 128, 256, 256, 256])\n",
    "output = net(data)\n",
    "print('output: ', output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('covid19-detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87965ae81f78e2cdd312b875e66f5e90c5b874a926d1c435d8904a4ed5347295"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
